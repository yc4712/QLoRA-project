# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4N20qCjbtMDFgtrbcFa4XDxKesieZdL
"""

# src/training_utils.py
import os
import json
import time
import math
import torch
import numpy as np
from transformers import TrainerCallback

class MemoryTracker:
    """Track GPU memory usage throughout training"""

    def __init__(self):
        self.reset()

    def reset(self):
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
        self.peak_memory_gb = 0.0

    def update(self):
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            self.peak_memory_gb = max(self.peak_memory_gb, allocated)
            return allocated, reserved
        return 0.0, 0.0

    def get_peak_memory(self):
        if torch.cuda.is_available():
            self.peak_memory_gb = max(
                self.peak_memory_gb,
                torch.cuda.max_memory_allocated() / 1e9,
            )
        return self.peak_memory_gb


def compute_perplexity(loss: float) -> float:
    try:
        return float(math.exp(loss))
    except OverflowError:
        return float("inf")


class TrainingMetrics:
    def __init__(self, name: str):
        self.name = name
        self.reset()

    def reset(self):
        self.epoch_times = []
        self.epoch_losses = []
        self.epoch_perplexities = []
        self.training_start_time = None
        self.training_end_time = None
        self.memory_tracker = MemoryTracker()

    def start_training(self):
        self.training_start_time = time.time()
        self.memory_tracker.reset()

    def end_training(self):
        self.training_end_time = time.time()

    def log_epoch(self, epoch_time: float, loss: float, perplexity: float):
        self.epoch_times.append(epoch_time)
        self.epoch_losses.append(loss)
        self.epoch_perplexities.append(perplexity)

    @property
    def total_time(self):
        if self.training_start_time is None or self.training_end_time is None:
            return 0.0
        return self.training_end_time - self.training_start_time

    def get_summary(self):
        peak_mem = self.memory_tracker.get_peak_memory()
        final_loss = self.epoch_losses[-1] if self.epoch_losses else None
        final_ppl = (
            self.epoch_perplexities[-1] if self.epoch_perplexities else None
        )
        return {
            "name": self.name,
            "total_training_time_hours": self.total_time / 3600 if self.total_time else None,
            "avg_epoch_time_minutes": np.mean(self.epoch_times) / 60
            if self.epoch_times
            else None,
            "peak_memory_gb": peak_mem,
            "final_loss": final_loss,
            "final_perplexity": final_ppl,
        }


class MetricsCallback(TrainerCallback):
    def __init__(self, metrics_tracker: TrainingMetrics):
        self.metrics_tracker = metrics_tracker
        self.epoch_start_time = None

    def on_epoch_begin(self, args, state, control, **kwargs):
        self.epoch_start_time = time.time()

    def on_epoch_end(self, args, state, control, **kwargs):
        if self.epoch_start_time is None:
            return
        epoch_time = time.time() - self.epoch_start_time
        logs = state.log_history
        if logs:
            last_log = logs[-1]
            loss = last_log.get("loss", 0)
            ppl = compute_perplexity(loss)
            self.metrics_tracker.log_epoch(epoch_time, loss, ppl)
            alloc, reserved = self.metrics_tracker.memory_tracker.update()
            print(
                f"\nEpoch {state.epoch:.0f} - "
                f"Loss: {loss:.4f}, PPL: {ppl:.4f}, "
                f"Time: {epoch_time/60:.2f} min, "
                f"GPU: {alloc:.2f} GB alloc / {reserved:.2f} GB reserved"
            )


def save_training_logs(trainer, metrics: TrainingMetrics, output_dir: str):
    os.makedirs(output_dir, exist_ok=True)

    if hasattr(trainer, "state") and hasattr(trainer.state, "log_history"):
        log_history_file = os.path.join(output_dir, "training_logs.json")
        with open(log_history_file, "w") as f:
            json.dump(trainer.state.log_history, f, indent=2)

    epoch_metrics = {
        "epoch_times": metrics.epoch_times,
        "epoch_losses": metrics.epoch_losses,
        "epoch_perplexities": metrics.epoch_perplexities,
        "total_training_time_seconds": metrics.total_time,
        "peak_memory_gb": metrics.memory_tracker.get_peak_memory(),
    }
    epoch_metrics_file = os.path.join(output_dir, "epoch_metrics.json")
    with open(epoch_metrics_file, "w") as f:
        json.dump(epoch_metrics, f, indent=2)

    if hasattr(trainer, "state"):
        trainer_state = {
            "best_metric": getattr(trainer.state, "best_metric", None),
            "best_model_checkpoint": getattr(
                trainer.state, "best_model_checkpoint", None
            ),
            "global_step": getattr(trainer.state, "global_step", None),
            "epoch": getattr(trainer.state, "epoch", None),
        }
        trainer_state_file = os.path.join(output_dir, "trainer_state.json")
        with open(trainer_state_file, "w") as f:
            json.dump(trainer_state, f, indent=2)


def save_evaluation_results(trainer, output_dir: str):
    os.makedirs(output_dir, exist_ok=True)
    eval_results = trainer.evaluate()
    eval_file = os.path.join(output_dir, "evaluation_results.json")
    with open(eval_file, "w") as f:
        json.dump(eval_results, f, indent=2)
    print(f"Saved evaluation results to {eval_file}")
    return eval_results