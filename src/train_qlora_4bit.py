# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4N20qCjbtMDFgtrbcFa4XDxKesieZdL
"""

# src/train_qlora_4bit.py
import argparse
from transformers import AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from data_prep import load_oasst1_splits
from training_utils import TrainingMetrics, MetricsCallback, save_training_logs, save_evaluation_results

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_name", type=str, default="meta-llama/Llama-2-7b-hf")
    parser.add_argument("--output_dir", type=str, default="results/llama7b_4bit_qlora")
    parser.add_argument("--num_epochs", type=int, default=3)
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--grad_accum_steps", type=int, default=4)
    parser.add_argument("--learning_rate", type=float, default=2e-4)
    parser.add_argument("--max_seq_length", type=int, default=1024)
    args = parser.parse_args()

    tokenized_train, tokenized_val, tokenizer = load_oasst1_splits(
        args.model_name, args.max_seq_length
    )

    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_use_double_quant=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype="bfloat16",
    )

    model = AutoModelForCausalLM.from_pretrained(
        args.model_name,
        quantization_config=bnb_config,
        device_map="auto",
        trust_remote_code=True,
    )
    model = prepare_model_for_kbit_training(model)

    lora_config = LoraConfig(
        r=64,
        lora_alpha=16,
        target_modules=[
            "q_proj",
            "k_proj",
            "v_proj",
            "o_proj",
            "gate_proj",
            "up_proj",
            "down_proj",
        ],
        lora_dropout=0.1,
        bias="none",
        task_type="CAUSAL_LM",
    )
    model = get_peft_model(model, lora_config)
    model.config.use_cache = False

    metrics = TrainingMetrics("4-bit QLoRA")
    metrics.start_training()
    metrics_callback = MetricsCallback(metrics)

    training_args = TrainingArguments(
        output_dir=args.output_dir,
        logging_dir=f"{args.output_dir}/logs",
        num_train_epochs=args.num_epochs,
        per_device_train_batch_size=args.batch_size,
        per_device_eval_batch_size=args.batch_size,
        gradient_accumulation_steps=args.grad_accum_steps,
        learning_rate=args.learning_rate,
        evaluation_strategy="steps",
        save_strategy="steps",
        logging_steps=10,
        eval_steps=50,
        save_steps=100,
        warmup_steps=100,
        group_by_length=True,
        max_grad_norm=0.3,
        adam_beta2=0.999,
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        report_to="none",
        logging_first_step=True,
        bf16=True,
        optim="paged_adamw_32bit",
        gradient_checkpointing=True,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_val,
        callbacks=[metrics_callback],
    )

    trainer.train()
    metrics.end_training()

    save_training_logs(trainer, metrics, args.output_dir)
    save_evaluation_results(trainer, args.output_dir)


if __name__ == "__main__":
    main()