[
  {
    "loss": 1.1871,
    "grad_norm": 0.08246059715747833,
    "learning_rate": 0.0,
    "epoch": 0.002178649237472767,
    "step": 1
  },
  {
    "loss": 1.3036,
    "grad_norm": 0.05920242518186569,
    "learning_rate": 1.8e-05,
    "epoch": 0.02178649237472767,
    "step": 10
  },
  {
    "loss": 1.2557,
    "grad_norm": 0.11583911627531052,
    "learning_rate": 3.8e-05,
    "epoch": 0.04357298474945534,
    "step": 20
  },
  {
    "loss": 1.1379,
    "grad_norm": 0.11547887325286865,
    "learning_rate": 5.8e-05,
    "epoch": 0.06535947712418301,
    "step": 30
  },
  {
    "loss": 1.1096,
    "grad_norm": 0.09320962429046631,
    "learning_rate": 7.800000000000001e-05,
    "epoch": 0.08714596949891068,
    "step": 40
  },
  {
    "loss": 1.1976,
    "grad_norm": 0.08215245604515076,
    "learning_rate": 9.8e-05,
    "epoch": 0.10893246187363835,
    "step": 50
  },
  {
    "eval_loss": 1.1671067476272583,
    "eval_runtime": 54.1626,
    "eval_samples_per_second": 7.108,
    "eval_steps_per_second": 1.791,
    "epoch": 0.10893246187363835,
    "step": 50
  },
  {
    "loss": 1.2026,
    "grad_norm": 0.09721820056438446,
    "learning_rate": 0.000118,
    "epoch": 0.13071895424836602,
    "step": 60
  },
  {
    "loss": 1.1629,
    "grad_norm": 0.08042643964290619,
    "learning_rate": 0.000138,
    "epoch": 0.15250544662309368,
    "step": 70
  },
  {
    "loss": 1.0842,
    "grad_norm": 0.09386922419071198,
    "learning_rate": 0.00015800000000000002,
    "epoch": 0.17429193899782136,
    "step": 80
  },
  {
    "loss": 1.0694,
    "grad_norm": 0.07981943339109421,
    "learning_rate": 0.00017800000000000002,
    "epoch": 0.19607843137254902,
    "step": 90
  },
  {
    "loss": 1.0979,
    "grad_norm": 0.09211529046297073,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.2178649237472767,
    "step": 100
  },
  {
    "eval_loss": 1.1484034061431885,
    "eval_runtime": 54.2723,
    "eval_samples_per_second": 7.094,
    "eval_steps_per_second": 1.787,
    "epoch": 0.2178649237472767,
    "step": 100
  },
  {
    "loss": 1.1512,
    "grad_norm": 0.07426758110523224,
    "learning_rate": 0.0001985904463586531,
    "epoch": 0.23965141612200436,
    "step": 110
  },
  {
    "loss": 1.1822,
    "grad_norm": 0.0812445804476738,
    "learning_rate": 0.00019702427564604542,
    "epoch": 0.26143790849673204,
    "step": 120
  },
  {
    "loss": 1.2207,
    "grad_norm": 0.10238368809223175,
    "learning_rate": 0.00019545810493343775,
    "epoch": 0.28322440087145967,
    "step": 130
  },
  {
    "loss": 1.0823,
    "grad_norm": 0.06250440329313278,
    "learning_rate": 0.00019389193422083008,
    "epoch": 0.30501089324618735,
    "step": 140
  },
  {
    "loss": 1.1179,
    "grad_norm": 0.09228057414293289,
    "learning_rate": 0.0001923257635082224,
    "epoch": 0.32679738562091504,
    "step": 150
  },
  {
    "eval_loss": 1.1481434106826782,
    "eval_runtime": 54.2381,
    "eval_samples_per_second": 7.098,
    "eval_steps_per_second": 1.788,
    "epoch": 0.32679738562091504,
    "step": 150
  },
  {
    "loss": 1.0957,
    "grad_norm": 0.07306075841188431,
    "learning_rate": 0.00019075959279561474,
    "epoch": 0.3485838779956427,
    "step": 160
  },
  {
    "loss": 1.101,
    "grad_norm": 0.07954363524913788,
    "learning_rate": 0.00018919342208300704,
    "epoch": 0.37037037037037035,
    "step": 170
  },
  {
    "loss": 1.0985,
    "grad_norm": 0.0865272581577301,
    "learning_rate": 0.00018762725137039937,
    "epoch": 0.39215686274509803,
    "step": 180
  },
  {
    "loss": 1.1858,
    "grad_norm": 0.06706542521715164,
    "learning_rate": 0.0001860610806577917,
    "epoch": 0.4139433551198257,
    "step": 190
  },
  {
    "loss": 1.1745,
    "grad_norm": 0.06119004637002945,
    "learning_rate": 0.00018449490994518403,
    "epoch": 0.4357298474945534,
    "step": 200
  },
  {
    "eval_loss": 1.1463319063186646,
    "eval_runtime": 54.2084,
    "eval_samples_per_second": 7.102,
    "eval_steps_per_second": 1.789,
    "epoch": 0.4357298474945534,
    "step": 200
  },
  {
    "loss": 1.1883,
    "grad_norm": 0.08613040298223495,
    "learning_rate": 0.00018292873923257636,
    "epoch": 0.45751633986928103,
    "step": 210
  },
  {
    "loss": 1.1225,
    "grad_norm": 0.07618007808923721,
    "learning_rate": 0.0001813625685199687,
    "epoch": 0.4793028322440087,
    "step": 220
  },
  {
    "loss": 1.1637,
    "grad_norm": 0.08637363463640213,
    "learning_rate": 0.00017979639780736102,
    "epoch": 0.5010893246187363,
    "step": 230
  },
  {
    "loss": 1.1598,
    "grad_norm": 0.07745763659477234,
    "learning_rate": 0.00017823022709475335,
    "epoch": 0.5228758169934641,
    "step": 240
  },
  {
    "loss": 1.0284,
    "grad_norm": 0.0713115781545639,
    "learning_rate": 0.00017666405638214566,
    "epoch": 0.5446623093681917,
    "step": 250
  },
  {
    "eval_loss": 1.140116572380066,
    "eval_runtime": 54.207,
    "eval_samples_per_second": 7.102,
    "eval_steps_per_second": 1.789,
    "epoch": 0.5446623093681917,
    "step": 250
  },
  {
    "loss": 1.0833,
    "grad_norm": 0.08704982697963715,
    "learning_rate": 0.000175097885669538,
    "epoch": 0.5664488017429193,
    "step": 260
  },
  {
    "loss": 1.1824,
    "grad_norm": 0.07707945257425308,
    "learning_rate": 0.00017353171495693032,
    "epoch": 0.5882352941176471,
    "step": 270
  },
  {
    "loss": 1.1497,
    "grad_norm": 0.0811108723282814,
    "learning_rate": 0.00017196554424432262,
    "epoch": 0.6100217864923747,
    "step": 280
  },
  {
    "loss": 1.1995,
    "grad_norm": 0.073213130235672,
    "learning_rate": 0.00017039937353171495,
    "epoch": 0.6318082788671024,
    "step": 290
  },
  {
    "loss": 1.1513,
    "grad_norm": 0.06979532539844513,
    "learning_rate": 0.00016883320281910728,
    "epoch": 0.6535947712418301,
    "step": 300
  },
  {
    "eval_loss": 1.1409721374511719,
    "eval_runtime": 54.1896,
    "eval_samples_per_second": 7.105,
    "eval_steps_per_second": 1.79,
    "epoch": 0.6535947712418301,
    "step": 300
  },
  {
    "loss": 1.1215,
    "grad_norm": 0.06892858445644379,
    "learning_rate": 0.0001672670321064996,
    "epoch": 0.6753812636165577,
    "step": 310
  },
  {
    "loss": 1.0979,
    "grad_norm": 0.07591632753610611,
    "learning_rate": 0.00016570086139389194,
    "epoch": 0.6971677559912854,
    "step": 320
  },
  {
    "loss": 1.1281,
    "grad_norm": 0.10098099708557129,
    "learning_rate": 0.00016413469068128427,
    "epoch": 0.7189542483660131,
    "step": 330
  },
  {
    "loss": 1.125,
    "grad_norm": 0.06769786030054092,
    "learning_rate": 0.0001625685199686766,
    "epoch": 0.7407407407407407,
    "step": 340
  },
  {
    "loss": 1.1631,
    "grad_norm": 0.08555854856967926,
    "learning_rate": 0.00016100234925606893,
    "epoch": 0.7625272331154684,
    "step": 350
  },
  {
    "eval_loss": 1.130478024482727,
    "eval_runtime": 54.0981,
    "eval_samples_per_second": 7.117,
    "eval_steps_per_second": 1.793,
    "epoch": 0.7625272331154684,
    "step": 350
  },
  {
    "loss": 1.0829,
    "grad_norm": 0.06909437477588654,
    "learning_rate": 0.00015943617854346123,
    "epoch": 0.7843137254901961,
    "step": 360
  },
  {
    "loss": 1.1446,
    "grad_norm": 0.07306212186813354,
    "learning_rate": 0.00015787000783085356,
    "epoch": 0.8061002178649237,
    "step": 370
  },
  {
    "loss": 1.1143,
    "grad_norm": 0.08400470018386841,
    "learning_rate": 0.0001563038371182459,
    "epoch": 0.8278867102396514,
    "step": 380
  },
  {
    "loss": 1.163,
    "grad_norm": 0.07909376174211502,
    "learning_rate": 0.00015473766640563822,
    "epoch": 0.8496732026143791,
    "step": 390
  },
  {
    "loss": 1.1035,
    "grad_norm": 0.08576391637325287,
    "learning_rate": 0.00015317149569303055,
    "epoch": 0.8714596949891068,
    "step": 400
  },
  {
    "eval_loss": 1.1327669620513916,
    "eval_runtime": 54.2143,
    "eval_samples_per_second": 7.101,
    "eval_steps_per_second": 1.789,
    "epoch": 0.8714596949891068,
    "step": 400
  },
  {
    "loss": 1.0168,
    "grad_norm": 0.08092092722654343,
    "learning_rate": 0.00015160532498042289,
    "epoch": 0.8932461873638344,
    "step": 410
  },
  {
    "loss": 1.107,
    "grad_norm": 0.0789194256067276,
    "learning_rate": 0.00015003915426781522,
    "epoch": 0.9150326797385621,
    "step": 420
  },
  {
    "loss": 1.1465,
    "grad_norm": 0.0645531564950943,
    "learning_rate": 0.00014847298355520755,
    "epoch": 0.9368191721132898,
    "step": 430
  },
  {
    "loss": 1.1608,
    "grad_norm": 0.06731299310922623,
    "learning_rate": 0.00014690681284259985,
    "epoch": 0.9586056644880174,
    "step": 440
  },
  {
    "loss": 1.0689,
    "grad_norm": 0.07737007737159729,
    "learning_rate": 0.00014534064212999218,
    "epoch": 0.9803921568627451,
    "step": 450
  },
  {
    "eval_loss": 1.1513164043426514,
    "eval_runtime": 54.1188,
    "eval_samples_per_second": 7.114,
    "eval_steps_per_second": 1.792,
    "epoch": 0.9803921568627451,
    "step": 450
  },
  {
    "loss": 1.1008,
    "grad_norm": 0.07491640001535416,
    "learning_rate": 0.00014377447141738448,
    "epoch": 1.0021786492374727,
    "step": 460
  },
  {
    "loss": 1.0282,
    "grad_norm": 0.07663556933403015,
    "learning_rate": 0.0001422083007047768,
    "epoch": 1.0239651416122004,
    "step": 470
  },
  {
    "loss": 0.971,
    "grad_norm": 0.10112965106964111,
    "learning_rate": 0.00014064212999216914,
    "epoch": 1.0457516339869282,
    "step": 480
  },
  {
    "loss": 1.0603,
    "grad_norm": 0.0925423800945282,
    "learning_rate": 0.00013907595927956147,
    "epoch": 1.0675381263616557,
    "step": 490
  },
  {
    "loss": 1.0638,
    "grad_norm": 0.08598393201828003,
    "learning_rate": 0.0001375097885669538,
    "epoch": 1.0893246187363834,
    "step": 500
  },
  {
    "eval_loss": 1.1644916534423828,
    "eval_runtime": 54.1224,
    "eval_samples_per_second": 7.114,
    "eval_steps_per_second": 1.792,
    "epoch": 1.0893246187363834,
    "step": 500
  },
  {
    "loss": 1.0657,
    "grad_norm": 0.11131280660629272,
    "learning_rate": 0.00013594361785434613,
    "epoch": 1.1111111111111112,
    "step": 510
  },
  {
    "loss": 1.1106,
    "grad_norm": 0.11899800598621368,
    "learning_rate": 0.00013437744714173846,
    "epoch": 1.132897603485839,
    "step": 520
  },
  {
    "loss": 0.9871,
    "grad_norm": 0.09712713956832886,
    "learning_rate": 0.0001328112764291308,
    "epoch": 1.1546840958605664,
    "step": 530
  },
  {
    "loss": 1.0907,
    "grad_norm": 0.11210481077432632,
    "learning_rate": 0.00013124510571652312,
    "epoch": 1.1764705882352942,
    "step": 540
  },
  {
    "loss": 1.0437,
    "grad_norm": 0.15263812243938446,
    "learning_rate": 0.00012967893500391543,
    "epoch": 1.1982570806100217,
    "step": 550
  },
  {
    "eval_loss": 1.146669626235962,
    "eval_runtime": 54.1685,
    "eval_samples_per_second": 7.107,
    "eval_steps_per_second": 1.791,
    "epoch": 1.1982570806100217,
    "step": 550
  },
  {
    "loss": 1.058,
    "grad_norm": 0.1025305911898613,
    "learning_rate": 0.00012811276429130776,
    "epoch": 1.2200435729847494,
    "step": 560
  },
  {
    "loss": 1.033,
    "grad_norm": 0.14360444247722626,
    "learning_rate": 0.00012654659357870009,
    "epoch": 1.2418300653594772,
    "step": 570
  },
  {
    "loss": 1.054,
    "grad_norm": 0.18144354224205017,
    "learning_rate": 0.00012498042286609242,
    "epoch": 1.263616557734205,
    "step": 580
  },
  {
    "loss": 1.082,
    "grad_norm": 0.1011376827955246,
    "learning_rate": 0.00012341425215348475,
    "epoch": 1.2854030501089324,
    "step": 590
  },
  {
    "loss": 1.0485,
    "grad_norm": 0.11682556569576263,
    "learning_rate": 0.00012184808144087708,
    "epoch": 1.3071895424836601,
    "step": 600
  },
  {
    "eval_loss": 1.1468946933746338,
    "eval_runtime": 54.2519,
    "eval_samples_per_second": 7.097,
    "eval_steps_per_second": 1.788,
    "epoch": 1.3071895424836601,
    "step": 600
  },
  {
    "loss": 1.0444,
    "grad_norm": 0.14281228184700012,
    "learning_rate": 0.00012028191072826939,
    "epoch": 1.3289760348583877,
    "step": 610
  },
  {
    "loss": 0.9961,
    "grad_norm": 0.13648506999015808,
    "learning_rate": 0.00011871574001566171,
    "epoch": 1.3507625272331154,
    "step": 620
  },
  {
    "loss": 1.061,
    "grad_norm": 0.12619048357009888,
    "learning_rate": 0.00011714956930305403,
    "epoch": 1.3725490196078431,
    "step": 630
  },
  {
    "loss": 1.0018,
    "grad_norm": 0.16050314903259277,
    "learning_rate": 0.00011558339859044636,
    "epoch": 1.3943355119825709,
    "step": 640
  },
  {
    "loss": 1.0453,
    "grad_norm": 0.13996751606464386,
    "learning_rate": 0.00011401722787783869,
    "epoch": 1.4161220043572984,
    "step": 650
  },
  {
    "eval_loss": 1.1443331241607666,
    "eval_runtime": 54.1044,
    "eval_samples_per_second": 7.116,
    "eval_steps_per_second": 1.793,
    "epoch": 1.4161220043572984,
    "step": 650
  },
  {
    "loss": 1.027,
    "grad_norm": 0.10817549377679825,
    "learning_rate": 0.00011245105716523102,
    "epoch": 1.4379084967320261,
    "step": 660
  },
  {
    "loss": 1.0214,
    "grad_norm": 0.119301937520504,
    "learning_rate": 0.00011088488645262333,
    "epoch": 1.4596949891067539,
    "step": 670
  },
  {
    "loss": 1.0498,
    "grad_norm": 0.09704265743494034,
    "learning_rate": 0.00010931871574001566,
    "epoch": 1.4814814814814814,
    "step": 680
  },
  {
    "loss": 0.9755,
    "grad_norm": 0.1370907723903656,
    "learning_rate": 0.00010775254502740799,
    "epoch": 1.5032679738562091,
    "step": 690
  },
  {
    "loss": 1.0629,
    "grad_norm": 0.11050712317228317,
    "learning_rate": 0.00010618637431480032,
    "epoch": 1.5250544662309369,
    "step": 700
  },
  {
    "eval_loss": 1.130407452583313,
    "eval_runtime": 54.1049,
    "eval_samples_per_second": 7.116,
    "eval_steps_per_second": 1.793,
    "epoch": 1.5250544662309369,
    "step": 700
  },
  {
    "loss": 1.0241,
    "grad_norm": 0.136052668094635,
    "learning_rate": 0.00010462020360219264,
    "epoch": 1.5468409586056646,
    "step": 710
  },
  {
    "loss": 1.1154,
    "grad_norm": 0.14338956773281097,
    "learning_rate": 0.00010305403288958497,
    "epoch": 1.5686274509803921,
    "step": 720
  },
  {
    "loss": 0.9827,
    "grad_norm": 0.10491307079792023,
    "learning_rate": 0.0001014878621769773,
    "epoch": 1.5904139433551199,
    "step": 730
  },
  {
    "loss": 0.9888,
    "grad_norm": 0.1374480128288269,
    "learning_rate": 9.992169146436962e-05,
    "epoch": 1.6122004357298474,
    "step": 740
  },
  {
    "loss": 0.9849,
    "grad_norm": 0.11163468658924103,
    "learning_rate": 9.835552075176195e-05,
    "epoch": 1.6339869281045751,
    "step": 750
  },
  {
    "eval_loss": 1.1484453678131104,
    "eval_runtime": 54.1419,
    "eval_samples_per_second": 7.111,
    "eval_steps_per_second": 1.792,
    "epoch": 1.6339869281045751,
    "step": 750
  },
  {
    "loss": 1.0555,
    "grad_norm": 0.11508063226938248,
    "learning_rate": 9.678935003915428e-05,
    "epoch": 1.6557734204793029,
    "step": 760
  },
  {
    "loss": 0.9783,
    "grad_norm": 0.12041974812746048,
    "learning_rate": 9.522317932654659e-05,
    "epoch": 1.6775599128540306,
    "step": 770
  },
  {
    "loss": 1.0492,
    "grad_norm": 0.10051171481609344,
    "learning_rate": 9.365700861393892e-05,
    "epoch": 1.6993464052287581,
    "step": 780
  },
  {
    "loss": 0.9751,
    "grad_norm": 0.13219113647937775,
    "learning_rate": 9.209083790133125e-05,
    "epoch": 1.7211328976034859,
    "step": 790
  },
  {
    "loss": 1.0164,
    "grad_norm": 0.13285374641418457,
    "learning_rate": 9.052466718872358e-05,
    "epoch": 1.7429193899782134,
    "step": 800
  },
  {
    "eval_loss": 1.1530637741088867,
    "eval_runtime": 54.3001,
    "eval_samples_per_second": 7.09,
    "eval_steps_per_second": 1.786,
    "epoch": 1.7429193899782134,
    "step": 800
  },
  {
    "loss": 0.9915,
    "grad_norm": 0.11423686891794205,
    "learning_rate": 8.89584964761159e-05,
    "epoch": 1.7647058823529411,
    "step": 810
  },
  {
    "loss": 1.0755,
    "grad_norm": 0.1293734461069107,
    "learning_rate": 8.739232576350823e-05,
    "epoch": 1.7864923747276689,
    "step": 820
  },
  {
    "loss": 1.0522,
    "grad_norm": 0.1153695210814476,
    "learning_rate": 8.582615505090055e-05,
    "epoch": 1.8082788671023966,
    "step": 830
  },
  {
    "loss": 1.0826,
    "grad_norm": 0.11750250309705734,
    "learning_rate": 8.425998433829288e-05,
    "epoch": 1.8300653594771243,
    "step": 840
  },
  {
    "loss": 1.0685,
    "grad_norm": 0.15405185520648956,
    "learning_rate": 8.26938136256852e-05,
    "epoch": 1.8518518518518519,
    "step": 850
  },
  {
    "eval_loss": 1.1223111152648926,
    "eval_runtime": 54.1495,
    "eval_samples_per_second": 7.11,
    "eval_steps_per_second": 1.791,
    "epoch": 1.8518518518518519,
    "step": 850
  },
  {
    "loss": 1.0321,
    "grad_norm": 0.13784731924533844,
    "learning_rate": 8.112764291307752e-05,
    "epoch": 1.8736383442265794,
    "step": 860
  },
  {
    "loss": 1.0503,
    "grad_norm": 0.10757500678300858,
    "learning_rate": 7.956147220046985e-05,
    "epoch": 1.8954248366013071,
    "step": 870
  },
  {
    "loss": 1.0422,
    "grad_norm": 0.1365170180797577,
    "learning_rate": 7.799530148786218e-05,
    "epoch": 1.9172113289760349,
    "step": 880
  },
  {
    "loss": 1.0424,
    "grad_norm": 0.12744824588298798,
    "learning_rate": 7.642913077525451e-05,
    "epoch": 1.9389978213507626,
    "step": 890
  },
  {
    "loss": 1.0027,
    "grad_norm": 0.12191309034824371,
    "learning_rate": 7.486296006264683e-05,
    "epoch": 1.9607843137254903,
    "step": 900
  },
  {
    "eval_loss": 1.15146005153656,
    "eval_runtime": 54.1511,
    "eval_samples_per_second": 7.11,
    "eval_steps_per_second": 1.791,
    "epoch": 1.9607843137254903,
    "step": 900
  },
  {
    "loss": 1.0002,
    "grad_norm": 0.14660121500492096,
    "learning_rate": 7.329678935003915e-05,
    "epoch": 1.9825708061002179,
    "step": 910
  },
  {
    "loss": 1.0017,
    "grad_norm": 0.13013502955436707,
    "learning_rate": 7.173061863743148e-05,
    "epoch": 2.0043572984749454,
    "step": 920
  },
  {
    "loss": 0.9263,
    "grad_norm": 0.13881273567676544,
    "learning_rate": 7.01644479248238e-05,
    "epoch": 2.026143790849673,
    "step": 930
  },
  {
    "loss": 0.9366,
    "grad_norm": 0.16522672772407532,
    "learning_rate": 6.859827721221614e-05,
    "epoch": 2.047930283224401,
    "step": 940
  },
  {
    "loss": 0.9416,
    "grad_norm": 0.13012756407260895,
    "learning_rate": 6.703210649960847e-05,
    "epoch": 2.0697167755991286,
    "step": 950
  },
  {
    "eval_loss": 1.1738120317459106,
    "eval_runtime": 54.1413,
    "eval_samples_per_second": 7.111,
    "eval_steps_per_second": 1.792,
    "epoch": 2.0697167755991286,
    "step": 950
  },
  {
    "loss": 0.9302,
    "grad_norm": 0.1668194681406021,
    "learning_rate": 6.546593578700078e-05,
    "epoch": 2.0915032679738563,
    "step": 960
  },
  {
    "loss": 0.8918,
    "grad_norm": 0.13295333087444305,
    "learning_rate": 6.389976507439311e-05,
    "epoch": 2.113289760348584,
    "step": 970
  },
  {
    "loss": 0.8816,
    "grad_norm": 0.1366209089756012,
    "learning_rate": 6.233359436178544e-05,
    "epoch": 2.1350762527233114,
    "step": 980
  },
  {
    "loss": 0.905,
    "grad_norm": 0.14582005143165588,
    "learning_rate": 6.076742364917777e-05,
    "epoch": 2.156862745098039,
    "step": 990
  },
  {
    "loss": 0.9003,
    "grad_norm": 0.12976744771003723,
    "learning_rate": 5.920125293657008e-05,
    "epoch": 2.178649237472767,
    "step": 1000
  },
  {
    "eval_loss": 1.1593068838119507,
    "eval_runtime": 54.1564,
    "eval_samples_per_second": 7.109,
    "eval_steps_per_second": 1.791,
    "epoch": 2.178649237472767,
    "step": 1000
  },
  {
    "loss": 0.9228,
    "grad_norm": 0.14305546879768372,
    "learning_rate": 5.7635082223962413e-05,
    "epoch": 2.2004357298474946,
    "step": 1010
  },
  {
    "loss": 0.8968,
    "grad_norm": 0.1890164613723755,
    "learning_rate": 5.606891151135474e-05,
    "epoch": 2.2222222222222223,
    "step": 1020
  },
  {
    "loss": 0.9422,
    "grad_norm": 0.14560434222221375,
    "learning_rate": 5.450274079874707e-05,
    "epoch": 2.24400871459695,
    "step": 1030
  },
  {
    "loss": 0.9145,
    "grad_norm": 0.15126970410346985,
    "learning_rate": 5.293657008613939e-05,
    "epoch": 2.265795206971678,
    "step": 1040
  },
  {
    "loss": 0.8904,
    "grad_norm": 0.17651651799678802,
    "learning_rate": 5.137039937353172e-05,
    "epoch": 2.287581699346405,
    "step": 1050
  },
  {
    "eval_loss": 1.162796139717102,
    "eval_runtime": 54.1571,
    "eval_samples_per_second": 7.109,
    "eval_steps_per_second": 1.791,
    "epoch": 2.287581699346405,
    "step": 1050
  },
  {
    "loss": 0.9628,
    "grad_norm": 0.17840389907360077,
    "learning_rate": 4.9804228660924044e-05,
    "epoch": 2.309368191721133,
    "step": 1060
  },
  {
    "loss": 0.9379,
    "grad_norm": 0.18119719624519348,
    "learning_rate": 4.823805794831637e-05,
    "epoch": 2.3311546840958606,
    "step": 1070
  },
  {
    "loss": 0.8777,
    "grad_norm": 0.21805791556835175,
    "learning_rate": 4.66718872357087e-05,
    "epoch": 2.3529411764705883,
    "step": 1080
  },
  {
    "loss": 0.871,
    "grad_norm": 0.1832907646894455,
    "learning_rate": 4.510571652310102e-05,
    "epoch": 2.374727668845316,
    "step": 1090
  },
  {
    "loss": 0.8848,
    "grad_norm": 0.19597013294696808,
    "learning_rate": 4.353954581049335e-05,
    "epoch": 2.3965141612200433,
    "step": 1100
  },
  {
    "eval_loss": 1.1774787902832031,
    "eval_runtime": 54.1587,
    "eval_samples_per_second": 7.109,
    "eval_steps_per_second": 1.791,
    "epoch": 2.3965141612200433,
    "step": 1100
  },
  {
    "loss": 0.9074,
    "grad_norm": 0.1432504802942276,
    "learning_rate": 4.197337509788567e-05,
    "epoch": 2.418300653594771,
    "step": 1110
  },
  {
    "loss": 0.8786,
    "grad_norm": 0.14365863800048828,
    "learning_rate": 4.0407204385278e-05,
    "epoch": 2.440087145969499,
    "step": 1120
  },
  {
    "loss": 0.8886,
    "grad_norm": 0.17573994398117065,
    "learning_rate": 3.884103367267033e-05,
    "epoch": 2.4618736383442266,
    "step": 1130
  },
  {
    "loss": 0.9691,
    "grad_norm": 0.19735901057720184,
    "learning_rate": 3.727486296006265e-05,
    "epoch": 2.4836601307189543,
    "step": 1140
  },
  {
    "loss": 0.8915,
    "grad_norm": 0.1648566573858261,
    "learning_rate": 3.5708692247454974e-05,
    "epoch": 2.505446623093682,
    "step": 1150
  },
  {
    "eval_loss": 1.1765140295028687,
    "eval_runtime": 54.2486,
    "eval_samples_per_second": 7.097,
    "eval_steps_per_second": 1.788,
    "epoch": 2.505446623093682,
    "step": 1150
  },
  {
    "loss": 0.9204,
    "grad_norm": 0.17542865872383118,
    "learning_rate": 3.41425215348473e-05,
    "epoch": 2.52723311546841,
    "step": 1160
  },
  {
    "loss": 0.9094,
    "grad_norm": 0.15144751965999603,
    "learning_rate": 3.257635082223963e-05,
    "epoch": 2.549019607843137,
    "step": 1170
  },
  {
    "loss": 0.9659,
    "grad_norm": 0.18343719840049744,
    "learning_rate": 3.101018010963195e-05,
    "epoch": 2.570806100217865,
    "step": 1180
  },
  {
    "loss": 0.8771,
    "grad_norm": 0.204816535115242,
    "learning_rate": 2.9444009397024274e-05,
    "epoch": 2.5925925925925926,
    "step": 1190
  },
  {
    "loss": 0.9057,
    "grad_norm": 0.1594313383102417,
    "learning_rate": 2.78778386844166e-05,
    "epoch": 2.6143790849673203,
    "step": 1200
  },
  {
    "eval_loss": 1.1560956239700317,
    "eval_runtime": 54.274,
    "eval_samples_per_second": 7.094,
    "eval_steps_per_second": 1.787,
    "epoch": 2.6143790849673203,
    "step": 1200
  },
  {
    "loss": 0.9441,
    "grad_norm": 0.16381868720054626,
    "learning_rate": 2.6311667971808927e-05,
    "epoch": 2.636165577342048,
    "step": 1210
  },
  {
    "loss": 0.9101,
    "grad_norm": 0.16754001379013062,
    "learning_rate": 2.4745497259201254e-05,
    "epoch": 2.6579520697167753,
    "step": 1220
  },
  {
    "loss": 0.9474,
    "grad_norm": 0.1638527512550354,
    "learning_rate": 2.317932654659358e-05,
    "epoch": 2.6797385620915035,
    "step": 1230
  },
  {
    "loss": 0.8305,
    "grad_norm": 0.18498946726322174,
    "learning_rate": 2.1613155833985904e-05,
    "epoch": 2.701525054466231,
    "step": 1240
  },
  {
    "loss": 0.8716,
    "grad_norm": 0.15418042242527008,
    "learning_rate": 2.004698512137823e-05,
    "epoch": 2.7233115468409586,
    "step": 1250
  },
  {
    "eval_loss": 1.1857069730758667,
    "eval_runtime": 54.271,
    "eval_samples_per_second": 7.094,
    "eval_steps_per_second": 1.787,
    "epoch": 2.7233115468409586,
    "step": 1250
  },
  {
    "loss": 0.9412,
    "grad_norm": 0.18348078429698944,
    "learning_rate": 1.8480814408770558e-05,
    "epoch": 2.7450980392156863,
    "step": 1260
  },
  {
    "loss": 0.8298,
    "grad_norm": 0.17723694443702698,
    "learning_rate": 1.691464369616288e-05,
    "epoch": 2.766884531590414,
    "step": 1270
  },
  {
    "loss": 0.8015,
    "grad_norm": 0.2283312827348709,
    "learning_rate": 1.5348472983555208e-05,
    "epoch": 2.7886710239651418,
    "step": 1280
  },
  {
    "loss": 0.8972,
    "grad_norm": 0.2232731133699417,
    "learning_rate": 1.3782302270947534e-05,
    "epoch": 2.810457516339869,
    "step": 1290
  },
  {
    "loss": 0.8971,
    "grad_norm": 0.15957820415496826,
    "learning_rate": 1.221613155833986e-05,
    "epoch": 2.832244008714597,
    "step": 1300
  },
  {
    "eval_loss": 1.1722904443740845,
    "eval_runtime": 54.1575,
    "eval_samples_per_second": 7.109,
    "eval_steps_per_second": 1.791,
    "epoch": 2.832244008714597,
    "step": 1300
  },
  {
    "loss": 0.8601,
    "grad_norm": 0.18455980718135834,
    "learning_rate": 1.0649960845732184e-05,
    "epoch": 2.8540305010893245,
    "step": 1310
  },
  {
    "loss": 0.911,
    "grad_norm": 0.1448366940021515,
    "learning_rate": 9.083790133124511e-06,
    "epoch": 2.8758169934640523,
    "step": 1320
  },
  {
    "loss": 0.9143,
    "grad_norm": 0.2097291648387909,
    "learning_rate": 7.517619420516837e-06,
    "epoch": 2.89760348583878,
    "step": 1330
  },
  {
    "loss": 0.8705,
    "grad_norm": 0.2177167683839798,
    "learning_rate": 5.951448707909162e-06,
    "epoch": 2.9193899782135078,
    "step": 1340
  },
  {
    "loss": 0.9247,
    "grad_norm": 0.22894054651260376,
    "learning_rate": 4.385277995301488e-06,
    "epoch": 2.9411764705882355,
    "step": 1350
  },
  {
    "eval_loss": 1.16579008102417,
    "eval_runtime": 54.3569,
    "eval_samples_per_second": 7.083,
    "eval_steps_per_second": 1.785,
    "epoch": 2.9411764705882355,
    "step": 1350
  },
  {
    "loss": 0.9379,
    "grad_norm": 0.1717667132616043,
    "learning_rate": 2.8191072826938138e-06,
    "epoch": 2.962962962962963,
    "step": 1360
  },
  {
    "loss": 0.8817,
    "grad_norm": 0.17920731008052826,
    "learning_rate": 1.2529365700861394e-06,
    "epoch": 2.9847494553376905,
    "step": 1370
  },
  {
    "train_runtime": 11889.7318,
    "train_samples_per_second": 1.853,
    "train_steps_per_second": 0.116,
    "total_flos": 9.159216066000323e+17,
    "train_loss": 1.0254173743698851,
    "epoch": 3.0,
    "step": 1377
  },
  {
    "eval_loss": 1.1429808139801025,
    "eval_runtime": 54.1529,
    "eval_samples_per_second": 7.109,
    "eval_steps_per_second": 1.791,
    "epoch": 3.0,
    "step": 1377
  },
  {
    "eval_loss": 1.1465948820114136,
    "eval_runtime": 54.1811,
    "eval_samples_per_second": 7.106,
    "eval_steps_per_second": 1.79,
    "epoch": 3.0,
    "step": 1377
  }
]