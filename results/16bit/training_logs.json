[
  {
    "loss": 1.1566,
    "grad_norm": 0.07322218269109726,
    "learning_rate": 0.0,
    "epoch": 0.002178649237472767,
    "step": 1
  },
  {
    "loss": 1.2728,
    "grad_norm": 0.050733111798763275,
    "learning_rate": 1.8e-05,
    "epoch": 0.02178649237472767,
    "step": 10
  },
  {
    "loss": 1.2327,
    "grad_norm": 0.08201085776090622,
    "learning_rate": 3.8e-05,
    "epoch": 0.04357298474945534,
    "step": 20
  },
  {
    "loss": 1.1171,
    "grad_norm": 0.10562699288129807,
    "learning_rate": 5.8e-05,
    "epoch": 0.06535947712418301,
    "step": 30
  },
  {
    "loss": 1.0889,
    "grad_norm": 0.09875168651342392,
    "learning_rate": 7.800000000000001e-05,
    "epoch": 0.08714596949891068,
    "step": 40
  },
  {
    "loss": 1.1782,
    "grad_norm": 0.07576970756053925,
    "learning_rate": 9.8e-05,
    "epoch": 0.10893246187363835,
    "step": 50
  },
  {
    "eval_loss": 1.1476994752883911,
    "eval_runtime": 41.5128,
    "eval_samples_per_second": 9.274,
    "eval_steps_per_second": 2.337,
    "epoch": 0.10893246187363835,
    "step": 50
  },
  {
    "loss": 1.184,
    "grad_norm": 0.08001534640789032,
    "learning_rate": 0.000118,
    "epoch": 0.13071895424836602,
    "step": 60
  },
  {
    "loss": 1.1435,
    "grad_norm": 0.07136542350053787,
    "learning_rate": 0.000138,
    "epoch": 0.15250544662309368,
    "step": 70
  },
  {
    "loss": 1.0667,
    "grad_norm": 0.0822773426771164,
    "learning_rate": 0.00015800000000000002,
    "epoch": 0.17429193899782136,
    "step": 80
  },
  {
    "loss": 1.0518,
    "grad_norm": 0.0682007223367691,
    "learning_rate": 0.00017800000000000002,
    "epoch": 0.19607843137254902,
    "step": 90
  },
  {
    "loss": 1.0807,
    "grad_norm": 0.07882989943027496,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.2178649237472767,
    "step": 100
  },
  {
    "eval_loss": 1.1320627927780151,
    "eval_runtime": 41.5178,
    "eval_samples_per_second": 9.273,
    "eval_steps_per_second": 2.336,
    "epoch": 0.2178649237472767,
    "step": 100
  },
  {
    "loss": 1.1332,
    "grad_norm": 0.07445567101240158,
    "learning_rate": 0.0001985904463586531,
    "epoch": 0.23965141612200436,
    "step": 110
  },
  {
    "loss": 1.1642,
    "grad_norm": 0.07325305789709091,
    "learning_rate": 0.00019702427564604542,
    "epoch": 0.26143790849673204,
    "step": 120
  },
  {
    "loss": 1.2034,
    "grad_norm": 0.08204280585050583,
    "learning_rate": 0.00019545810493343775,
    "epoch": 0.28322440087145967,
    "step": 130
  },
  {
    "loss": 1.0664,
    "grad_norm": 0.05560695007443428,
    "learning_rate": 0.00019389193422083008,
    "epoch": 0.30501089324618735,
    "step": 140
  },
  {
    "loss": 1.1015,
    "grad_norm": 0.08540810644626617,
    "learning_rate": 0.0001923257635082224,
    "epoch": 0.32679738562091504,
    "step": 150
  },
  {
    "eval_loss": 1.1310607194900513,
    "eval_runtime": 41.5155,
    "eval_samples_per_second": 9.274,
    "eval_steps_per_second": 2.336,
    "epoch": 0.32679738562091504,
    "step": 150
  },
  {
    "loss": 1.0809,
    "grad_norm": 0.06176129728555679,
    "learning_rate": 0.00019075959279561474,
    "epoch": 0.3485838779956427,
    "step": 160
  },
  {
    "loss": 1.084,
    "grad_norm": 0.07001373171806335,
    "learning_rate": 0.00018919342208300704,
    "epoch": 0.37037037037037035,
    "step": 170
  },
  {
    "loss": 1.0831,
    "grad_norm": 0.07886084169149399,
    "learning_rate": 0.00018762725137039937,
    "epoch": 0.39215686274509803,
    "step": 180
  },
  {
    "loss": 1.1698,
    "grad_norm": 0.07658329606056213,
    "learning_rate": 0.0001860610806577917,
    "epoch": 0.4139433551198257,
    "step": 190
  },
  {
    "loss": 1.1569,
    "grad_norm": 0.05588330328464508,
    "learning_rate": 0.00018449490994518403,
    "epoch": 0.4357298474945534,
    "step": 200
  },
  {
    "eval_loss": 1.130203127861023,
    "eval_runtime": 41.516,
    "eval_samples_per_second": 9.274,
    "eval_steps_per_second": 2.336,
    "epoch": 0.4357298474945534,
    "step": 200
  },
  {
    "loss": 1.1723,
    "grad_norm": 0.07593932002782822,
    "learning_rate": 0.00018292873923257636,
    "epoch": 0.45751633986928103,
    "step": 210
  },
  {
    "loss": 1.1064,
    "grad_norm": 0.06126563251018524,
    "learning_rate": 0.0001813625685199687,
    "epoch": 0.4793028322440087,
    "step": 220
  },
  {
    "loss": 1.1476,
    "grad_norm": 0.07535376399755478,
    "learning_rate": 0.00017979639780736102,
    "epoch": 0.5010893246187363,
    "step": 230
  },
  {
    "loss": 1.1425,
    "grad_norm": 0.06686323881149292,
    "learning_rate": 0.00017823022709475335,
    "epoch": 0.5228758169934641,
    "step": 240
  },
  {
    "loss": 1.0122,
    "grad_norm": 0.06011621654033661,
    "learning_rate": 0.00017666405638214566,
    "epoch": 0.5446623093681917,
    "step": 250
  },
  {
    "eval_loss": 1.1244597434997559,
    "eval_runtime": 41.5174,
    "eval_samples_per_second": 9.273,
    "eval_steps_per_second": 2.336,
    "epoch": 0.5446623093681917,
    "step": 250
  },
  {
    "loss": 1.0663,
    "grad_norm": 0.07628659904003143,
    "learning_rate": 0.000175097885669538,
    "epoch": 0.5664488017429193,
    "step": 260
  },
  {
    "loss": 1.1663,
    "grad_norm": 0.07113263010978699,
    "learning_rate": 0.00017353171495693032,
    "epoch": 0.5882352941176471,
    "step": 270
  },
  {
    "loss": 1.1375,
    "grad_norm": 0.06974125653505325,
    "learning_rate": 0.00017196554424432262,
    "epoch": 0.6100217864923747,
    "step": 280
  },
  {
    "loss": 1.1841,
    "grad_norm": 0.06489673256874084,
    "learning_rate": 0.00017039937353171495,
    "epoch": 0.6318082788671024,
    "step": 290
  },
  {
    "loss": 1.1349,
    "grad_norm": 0.06336608529090881,
    "learning_rate": 0.00016883320281910728,
    "epoch": 0.6535947712418301,
    "step": 300
  },
  {
    "eval_loss": 1.124959945678711,
    "eval_runtime": 41.5247,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 0.6535947712418301,
    "step": 300
  },
  {
    "loss": 1.1051,
    "grad_norm": 0.07131826877593994,
    "learning_rate": 0.0001672670321064996,
    "epoch": 0.6753812636165577,
    "step": 310
  },
  {
    "loss": 1.0853,
    "grad_norm": 0.06700789928436279,
    "learning_rate": 0.00016570086139389194,
    "epoch": 0.6971677559912854,
    "step": 320
  },
  {
    "loss": 1.114,
    "grad_norm": 0.08094029873609543,
    "learning_rate": 0.00016413469068128427,
    "epoch": 0.7189542483660131,
    "step": 330
  },
  {
    "loss": 1.1093,
    "grad_norm": 0.055772289633750916,
    "learning_rate": 0.0001625685199686766,
    "epoch": 0.7407407407407407,
    "step": 340
  },
  {
    "loss": 1.1485,
    "grad_norm": 0.08101243525743484,
    "learning_rate": 0.00016100234925606893,
    "epoch": 0.7625272331154684,
    "step": 350
  },
  {
    "eval_loss": 1.115601658821106,
    "eval_runtime": 41.5224,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 0.7625272331154684,
    "step": 350
  },
  {
    "loss": 1.0696,
    "grad_norm": 0.06372082233428955,
    "learning_rate": 0.00015943617854346123,
    "epoch": 0.7843137254901961,
    "step": 360
  },
  {
    "loss": 1.1283,
    "grad_norm": 0.06641422212123871,
    "learning_rate": 0.00015787000783085356,
    "epoch": 0.8061002178649237,
    "step": 370
  },
  {
    "loss": 1.1004,
    "grad_norm": 0.07786386460065842,
    "learning_rate": 0.0001563038371182459,
    "epoch": 0.8278867102396514,
    "step": 380
  },
  {
    "loss": 1.1488,
    "grad_norm": 0.07276809960603714,
    "learning_rate": 0.00015473766640563822,
    "epoch": 0.8496732026143791,
    "step": 390
  },
  {
    "loss": 1.0896,
    "grad_norm": 0.07916228473186493,
    "learning_rate": 0.00015317149569303055,
    "epoch": 0.8714596949891068,
    "step": 400
  },
  {
    "eval_loss": 1.118034839630127,
    "eval_runtime": 41.5242,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 0.8714596949891068,
    "step": 400
  },
  {
    "loss": 1.0033,
    "grad_norm": 0.07179424166679382,
    "learning_rate": 0.00015160532498042289,
    "epoch": 0.8932461873638344,
    "step": 410
  },
  {
    "loss": 1.0933,
    "grad_norm": 0.07394427806138992,
    "learning_rate": 0.00015003915426781522,
    "epoch": 0.9150326797385621,
    "step": 420
  },
  {
    "loss": 1.1321,
    "grad_norm": 0.0631842166185379,
    "learning_rate": 0.00014847298355520755,
    "epoch": 0.9368191721132898,
    "step": 430
  },
  {
    "loss": 1.1474,
    "grad_norm": 0.06146128103137016,
    "learning_rate": 0.00014690681284259985,
    "epoch": 0.9586056644880174,
    "step": 440
  },
  {
    "loss": 1.0531,
    "grad_norm": 0.07043364644050598,
    "learning_rate": 0.00014534064212999218,
    "epoch": 0.9803921568627451,
    "step": 450
  },
  {
    "eval_loss": 1.136445164680481,
    "eval_runtime": 41.5293,
    "eval_samples_per_second": 9.271,
    "eval_steps_per_second": 2.336,
    "epoch": 0.9803921568627451,
    "step": 450
  },
  {
    "loss": 1.0879,
    "grad_norm": 0.06814537942409515,
    "learning_rate": 0.00014377447141738448,
    "epoch": 1.0021786492374727,
    "step": 460
  },
  {
    "loss": 1.0173,
    "grad_norm": 0.07074236869812012,
    "learning_rate": 0.0001422083007047768,
    "epoch": 1.0239651416122004,
    "step": 470
  },
  {
    "loss": 0.9605,
    "grad_norm": 0.09189895540475845,
    "learning_rate": 0.00014064212999216914,
    "epoch": 1.0457516339869282,
    "step": 480
  },
  {
    "loss": 1.0494,
    "grad_norm": 0.0868908017873764,
    "learning_rate": 0.00013907595927956147,
    "epoch": 1.0675381263616557,
    "step": 490
  },
  {
    "loss": 1.0527,
    "grad_norm": 0.07798432558774948,
    "learning_rate": 0.0001375097885669538,
    "epoch": 1.0893246187363834,
    "step": 500
  },
  {
    "eval_loss": 1.1498548984527588,
    "eval_runtime": 41.5213,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 1.0893246187363834,
    "step": 500
  },
  {
    "loss": 1.0541,
    "grad_norm": 0.10527991503477097,
    "learning_rate": 0.00013594361785434613,
    "epoch": 1.1111111111111112,
    "step": 510
  },
  {
    "loss": 1.0987,
    "grad_norm": 0.11219482123851776,
    "learning_rate": 0.00013437744714173846,
    "epoch": 1.132897603485839,
    "step": 520
  },
  {
    "loss": 0.9756,
    "grad_norm": 0.09215135127305984,
    "learning_rate": 0.0001328112764291308,
    "epoch": 1.1546840958605664,
    "step": 530
  },
  {
    "loss": 1.0793,
    "grad_norm": 0.10727940499782562,
    "learning_rate": 0.00013124510571652312,
    "epoch": 1.1764705882352942,
    "step": 540
  },
  {
    "loss": 1.0307,
    "grad_norm": 0.13029450178146362,
    "learning_rate": 0.00012967893500391543,
    "epoch": 1.1982570806100217,
    "step": 550
  },
  {
    "eval_loss": 1.1316280364990234,
    "eval_runtime": 41.5244,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 1.1982570806100217,
    "step": 550
  },
  {
    "loss": 1.0478,
    "grad_norm": 0.09469440579414368,
    "learning_rate": 0.00012811276429130776,
    "epoch": 1.2200435729847494,
    "step": 560
  },
  {
    "loss": 1.0216,
    "grad_norm": 0.1355465203523636,
    "learning_rate": 0.00012654659357870009,
    "epoch": 1.2418300653594772,
    "step": 570
  },
  {
    "loss": 1.0427,
    "grad_norm": 0.17025133967399597,
    "learning_rate": 0.00012498042286609242,
    "epoch": 1.263616557734205,
    "step": 580
  },
  {
    "loss": 1.0713,
    "grad_norm": 0.09660355746746063,
    "learning_rate": 0.00012341425215348475,
    "epoch": 1.2854030501089324,
    "step": 590
  },
  {
    "loss": 1.0358,
    "grad_norm": 0.11032667011022568,
    "learning_rate": 0.00012184808144087708,
    "epoch": 1.3071895424836601,
    "step": 600
  },
  {
    "eval_loss": 1.1335984468460083,
    "eval_runtime": 41.5199,
    "eval_samples_per_second": 9.273,
    "eval_steps_per_second": 2.336,
    "epoch": 1.3071895424836601,
    "step": 600
  },
  {
    "loss": 1.0331,
    "grad_norm": 0.1350872814655304,
    "learning_rate": 0.00012028191072826939,
    "epoch": 1.3289760348583877,
    "step": 610
  },
  {
    "loss": 0.9841,
    "grad_norm": 0.13108569383621216,
    "learning_rate": 0.00011871574001566171,
    "epoch": 1.3507625272331154,
    "step": 620
  },
  {
    "loss": 1.0484,
    "grad_norm": 0.12035771459341049,
    "learning_rate": 0.00011714956930305403,
    "epoch": 1.3725490196078431,
    "step": 630
  },
  {
    "loss": 0.9909,
    "grad_norm": 0.15759442746639252,
    "learning_rate": 0.00011558339859044636,
    "epoch": 1.3943355119825709,
    "step": 640
  },
  {
    "loss": 1.0339,
    "grad_norm": 0.127580925822258,
    "learning_rate": 0.00011401722787783869,
    "epoch": 1.4161220043572984,
    "step": 650
  },
  {
    "eval_loss": 1.1288431882858276,
    "eval_runtime": 41.5183,
    "eval_samples_per_second": 9.273,
    "eval_steps_per_second": 2.336,
    "epoch": 1.4161220043572984,
    "step": 650
  },
  {
    "loss": 1.0158,
    "grad_norm": 0.10448621958494186,
    "learning_rate": 0.00011245105716523102,
    "epoch": 1.4379084967320261,
    "step": 660
  },
  {
    "loss": 1.0088,
    "grad_norm": 0.11651451140642166,
    "learning_rate": 0.00011088488645262333,
    "epoch": 1.4596949891067539,
    "step": 670
  },
  {
    "loss": 1.0357,
    "grad_norm": 0.09520239382982254,
    "learning_rate": 0.00010931871574001566,
    "epoch": 1.4814814814814814,
    "step": 680
  },
  {
    "loss": 0.9645,
    "grad_norm": 0.12914331257343292,
    "learning_rate": 0.00010775254502740799,
    "epoch": 1.5032679738562091,
    "step": 690
  },
  {
    "loss": 1.0493,
    "grad_norm": 0.10863856971263885,
    "learning_rate": 0.00010618637431480032,
    "epoch": 1.5250544662309369,
    "step": 700
  },
  {
    "eval_loss": 1.1163657903671265,
    "eval_runtime": 41.5152,
    "eval_samples_per_second": 9.274,
    "eval_steps_per_second": 2.336,
    "epoch": 1.5250544662309369,
    "step": 700
  },
  {
    "loss": 1.0127,
    "grad_norm": 0.13438226282596588,
    "learning_rate": 0.00010462020360219264,
    "epoch": 1.5468409586056646,
    "step": 710
  },
  {
    "loss": 1.102,
    "grad_norm": 0.14025382697582245,
    "learning_rate": 0.00010305403288958497,
    "epoch": 1.5686274509803921,
    "step": 720
  },
  {
    "loss": 0.9709,
    "grad_norm": 0.10077046602964401,
    "learning_rate": 0.0001014878621769773,
    "epoch": 1.5904139433551199,
    "step": 730
  },
  {
    "loss": 0.9763,
    "grad_norm": 0.1298723965883255,
    "learning_rate": 9.992169146436962e-05,
    "epoch": 1.6122004357298474,
    "step": 740
  },
  {
    "loss": 0.975,
    "grad_norm": 0.11088307201862335,
    "learning_rate": 9.835552075176195e-05,
    "epoch": 1.6339869281045751,
    "step": 750
  },
  {
    "eval_loss": 1.1337248086929321,
    "eval_runtime": 41.5222,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 1.6339869281045751,
    "step": 750
  },
  {
    "loss": 1.0438,
    "grad_norm": 0.10988582670688629,
    "learning_rate": 9.678935003915428e-05,
    "epoch": 1.6557734204793029,
    "step": 760
  },
  {
    "loss": 0.9664,
    "grad_norm": 0.11802556365728378,
    "learning_rate": 9.522317932654659e-05,
    "epoch": 1.6775599128540306,
    "step": 770
  },
  {
    "loss": 1.0369,
    "grad_norm": 0.09600253403186798,
    "learning_rate": 9.365700861393892e-05,
    "epoch": 1.6993464052287581,
    "step": 780
  },
  {
    "loss": 0.9624,
    "grad_norm": 0.12539465725421906,
    "learning_rate": 9.209083790133125e-05,
    "epoch": 1.7211328976034859,
    "step": 790
  },
  {
    "loss": 1.0058,
    "grad_norm": 0.12245071679353714,
    "learning_rate": 9.052466718872358e-05,
    "epoch": 1.7429193899782134,
    "step": 800
  },
  {
    "eval_loss": 1.1387611627578735,
    "eval_runtime": 41.5223,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 1.7429193899782134,
    "step": 800
  },
  {
    "loss": 0.9773,
    "grad_norm": 0.10721010714769363,
    "learning_rate": 8.89584964761159e-05,
    "epoch": 1.7647058823529411,
    "step": 810
  },
  {
    "loss": 1.0641,
    "grad_norm": 0.12171255052089691,
    "learning_rate": 8.739232576350823e-05,
    "epoch": 1.7864923747276689,
    "step": 820
  },
  {
    "loss": 1.0398,
    "grad_norm": 0.10875516384840012,
    "learning_rate": 8.582615505090055e-05,
    "epoch": 1.8082788671023966,
    "step": 830
  },
  {
    "loss": 1.0704,
    "grad_norm": 0.10606474429368973,
    "learning_rate": 8.425998433829288e-05,
    "epoch": 1.8300653594771243,
    "step": 840
  },
  {
    "loss": 1.0553,
    "grad_norm": 0.14694185554981232,
    "learning_rate": 8.26938136256852e-05,
    "epoch": 1.8518518518518519,
    "step": 850
  },
  {
    "eval_loss": 1.108285903930664,
    "eval_runtime": 41.5227,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 1.8518518518518519,
    "step": 850
  },
  {
    "loss": 1.0187,
    "grad_norm": 0.13946586847305298,
    "learning_rate": 8.112764291307752e-05,
    "epoch": 1.8736383442265794,
    "step": 860
  },
  {
    "loss": 1.0382,
    "grad_norm": 0.10624951869249344,
    "learning_rate": 7.956147220046985e-05,
    "epoch": 1.8954248366013071,
    "step": 870
  },
  {
    "loss": 1.0309,
    "grad_norm": 0.13057298958301544,
    "learning_rate": 7.799530148786218e-05,
    "epoch": 1.9172113289760349,
    "step": 880
  },
  {
    "loss": 1.0294,
    "grad_norm": 0.12087307125329971,
    "learning_rate": 7.642913077525451e-05,
    "epoch": 1.9389978213507626,
    "step": 890
  },
  {
    "loss": 0.9917,
    "grad_norm": 0.11705949157476425,
    "learning_rate": 7.486296006264683e-05,
    "epoch": 1.9607843137254903,
    "step": 900
  },
  {
    "eval_loss": 1.1377946138381958,
    "eval_runtime": 41.5196,
    "eval_samples_per_second": 9.273,
    "eval_steps_per_second": 2.336,
    "epoch": 1.9607843137254903,
    "step": 900
  },
  {
    "loss": 0.9885,
    "grad_norm": 0.1418757140636444,
    "learning_rate": 7.329678935003915e-05,
    "epoch": 1.9825708061002179,
    "step": 910
  },
  {
    "loss": 0.9897,
    "grad_norm": 0.12753896415233612,
    "learning_rate": 7.173061863743148e-05,
    "epoch": 2.0043572984749454,
    "step": 920
  },
  {
    "loss": 0.9171,
    "grad_norm": 0.13567686080932617,
    "learning_rate": 7.01644479248238e-05,
    "epoch": 2.026143790849673,
    "step": 930
  },
  {
    "loss": 0.9253,
    "grad_norm": 0.1650438904762268,
    "learning_rate": 6.859827721221614e-05,
    "epoch": 2.047930283224401,
    "step": 940
  },
  {
    "loss": 0.9299,
    "grad_norm": 0.12657612562179565,
    "learning_rate": 6.703210649960847e-05,
    "epoch": 2.0697167755991286,
    "step": 950
  },
  {
    "eval_loss": 1.1613529920578003,
    "eval_runtime": 41.5234,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 2.0697167755991286,
    "step": 950
  },
  {
    "loss": 0.9193,
    "grad_norm": 0.16400262713432312,
    "learning_rate": 6.546593578700078e-05,
    "epoch": 2.0915032679738563,
    "step": 960
  },
  {
    "loss": 0.8816,
    "grad_norm": 0.12731829285621643,
    "learning_rate": 6.389976507439311e-05,
    "epoch": 2.113289760348584,
    "step": 970
  },
  {
    "loss": 0.8712,
    "grad_norm": 0.12864774465560913,
    "learning_rate": 6.233359436178544e-05,
    "epoch": 2.1350762527233114,
    "step": 980
  },
  {
    "loss": 0.894,
    "grad_norm": 0.13888958096504211,
    "learning_rate": 6.076742364917777e-05,
    "epoch": 2.156862745098039,
    "step": 990
  },
  {
    "loss": 0.8901,
    "grad_norm": 0.12573151290416718,
    "learning_rate": 5.920125293657008e-05,
    "epoch": 2.178649237472767,
    "step": 1000
  },
  {
    "eval_loss": 1.1455292701721191,
    "eval_runtime": 41.5209,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 2.178649237472767,
    "step": 1000
  },
  {
    "loss": 0.9127,
    "grad_norm": 0.13798849284648895,
    "learning_rate": 5.7635082223962413e-05,
    "epoch": 2.2004357298474946,
    "step": 1010
  },
  {
    "loss": 0.8853,
    "grad_norm": 0.18672402203083038,
    "learning_rate": 5.606891151135474e-05,
    "epoch": 2.2222222222222223,
    "step": 1020
  },
  {
    "loss": 0.9326,
    "grad_norm": 0.1413872092962265,
    "learning_rate": 5.450274079874707e-05,
    "epoch": 2.24400871459695,
    "step": 1030
  },
  {
    "loss": 0.9045,
    "grad_norm": 0.1443120688199997,
    "learning_rate": 5.293657008613939e-05,
    "epoch": 2.265795206971678,
    "step": 1040
  },
  {
    "loss": 0.8783,
    "grad_norm": 0.16818739473819733,
    "learning_rate": 5.137039937353172e-05,
    "epoch": 2.287581699346405,
    "step": 1050
  },
  {
    "eval_loss": 1.1486504077911377,
    "eval_runtime": 41.5249,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 2.287581699346405,
    "step": 1050
  },
  {
    "loss": 0.9518,
    "grad_norm": 0.17253141105175018,
    "learning_rate": 4.9804228660924044e-05,
    "epoch": 2.309368191721133,
    "step": 1060
  },
  {
    "loss": 0.9269,
    "grad_norm": 0.17726047337055206,
    "learning_rate": 4.823805794831637e-05,
    "epoch": 2.3311546840958606,
    "step": 1070
  },
  {
    "loss": 0.8641,
    "grad_norm": 0.20653672516345978,
    "learning_rate": 4.66718872357087e-05,
    "epoch": 2.3529411764705883,
    "step": 1080
  },
  {
    "loss": 0.8591,
    "grad_norm": 0.1862717568874359,
    "learning_rate": 4.510571652310102e-05,
    "epoch": 2.374727668845316,
    "step": 1090
  },
  {
    "loss": 0.8728,
    "grad_norm": 0.18902604281902313,
    "learning_rate": 4.353954581049335e-05,
    "epoch": 2.3965141612200433,
    "step": 1100
  },
  {
    "eval_loss": 1.1639870405197144,
    "eval_runtime": 41.5243,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 2.3965141612200433,
    "step": 1100
  },
  {
    "loss": 0.8954,
    "grad_norm": 0.13836602866649628,
    "learning_rate": 4.197337509788567e-05,
    "epoch": 2.418300653594771,
    "step": 1110
  },
  {
    "loss": 0.8695,
    "grad_norm": 0.1361185908317566,
    "learning_rate": 4.0407204385278e-05,
    "epoch": 2.440087145969499,
    "step": 1120
  },
  {
    "loss": 0.8777,
    "grad_norm": 0.16781406104564667,
    "learning_rate": 3.884103367267033e-05,
    "epoch": 2.4618736383442266,
    "step": 1130
  },
  {
    "loss": 0.9579,
    "grad_norm": 0.18923556804656982,
    "learning_rate": 3.727486296006265e-05,
    "epoch": 2.4836601307189543,
    "step": 1140
  },
  {
    "loss": 0.8817,
    "grad_norm": 0.1590491384267807,
    "learning_rate": 3.5708692247454974e-05,
    "epoch": 2.505446623093682,
    "step": 1150
  },
  {
    "eval_loss": 1.1623022556304932,
    "eval_runtime": 41.525,
    "eval_samples_per_second": 9.272,
    "eval_steps_per_second": 2.336,
    "epoch": 2.505446623093682,
    "step": 1150
  },
  {
    "loss": 0.9111,
    "grad_norm": 0.1675925850868225,
    "learning_rate": 3.41425215348473e-05,
    "epoch": 2.52723311546841,
    "step": 1160
  },
  {
    "loss": 0.8988,
    "grad_norm": 0.14762353897094727,
    "learning_rate": 3.257635082223963e-05,
    "epoch": 2.549019607843137,
    "step": 1170
  },
  {
    "loss": 0.9556,
    "grad_norm": 0.17751362919807434,
    "learning_rate": 3.101018010963195e-05,
    "epoch": 2.570806100217865,
    "step": 1180
  },
  {
    "loss": 0.8687,
    "grad_norm": 0.19717532396316528,
    "learning_rate": 2.9444009397024274e-05,
    "epoch": 2.5925925925925926,
    "step": 1190
  },
  {
    "loss": 0.8951,
    "grad_norm": 0.15464161336421967,
    "learning_rate": 2.78778386844166e-05,
    "epoch": 2.6143790849673203,
    "step": 1200
  },
  {
    "eval_loss": 1.1425403356552124,
    "eval_runtime": 41.539,
    "eval_samples_per_second": 9.268,
    "eval_steps_per_second": 2.335,
    "epoch": 2.6143790849673203,
    "step": 1200
  },
  {
    "loss": 0.9344,
    "grad_norm": 0.1778855323791504,
    "learning_rate": 2.6311667971808927e-05,
    "epoch": 2.636165577342048,
    "step": 1210
  },
  {
    "loss": 0.8984,
    "grad_norm": 0.16374634206295013,
    "learning_rate": 2.4745497259201254e-05,
    "epoch": 2.6579520697167753,
    "step": 1220
  },
  {
    "loss": 0.9365,
    "grad_norm": 0.1651650369167328,
    "learning_rate": 2.317932654659358e-05,
    "epoch": 2.6797385620915035,
    "step": 1230
  },
  {
    "loss": 0.8212,
    "grad_norm": 0.17794691026210785,
    "learning_rate": 2.1613155833985904e-05,
    "epoch": 2.701525054466231,
    "step": 1240
  },
  {
    "loss": 0.8613,
    "grad_norm": 0.14461882412433624,
    "learning_rate": 2.004698512137823e-05,
    "epoch": 2.7233115468409586,
    "step": 1250
  },
  {
    "eval_loss": 1.171197772026062,
    "eval_runtime": 41.5361,
    "eval_samples_per_second": 9.269,
    "eval_steps_per_second": 2.335,
    "epoch": 2.7233115468409586,
    "step": 1250
  },
  {
    "loss": 0.9311,
    "grad_norm": 0.17643329501152039,
    "learning_rate": 1.8480814408770558e-05,
    "epoch": 2.7450980392156863,
    "step": 1260
  },
  {
    "loss": 0.8213,
    "grad_norm": 0.17283332347869873,
    "learning_rate": 1.691464369616288e-05,
    "epoch": 2.766884531590414,
    "step": 1270
  },
  {
    "loss": 0.7904,
    "grad_norm": 0.22369825839996338,
    "learning_rate": 1.5348472983555208e-05,
    "epoch": 2.7886710239651418,
    "step": 1280
  },
  {
    "loss": 0.8865,
    "grad_norm": 0.2098487764596939,
    "learning_rate": 1.3782302270947534e-05,
    "epoch": 2.810457516339869,
    "step": 1290
  },
  {
    "loss": 0.8877,
    "grad_norm": 0.13590100407600403,
    "learning_rate": 1.221613155833986e-05,
    "epoch": 2.832244008714597,
    "step": 1300
  },
  {
    "eval_loss": 1.1583995819091797,
    "eval_runtime": 41.5307,
    "eval_samples_per_second": 9.27,
    "eval_steps_per_second": 2.336,
    "epoch": 2.832244008714597,
    "step": 1300
  },
  {
    "loss": 0.8495,
    "grad_norm": 0.1798817217350006,
    "learning_rate": 1.0649960845732184e-05,
    "epoch": 2.8540305010893245,
    "step": 1310
  },
  {
    "loss": 0.901,
    "grad_norm": 0.13833872973918915,
    "learning_rate": 9.083790133124511e-06,
    "epoch": 2.8758169934640523,
    "step": 1320
  },
  {
    "loss": 0.9044,
    "grad_norm": 0.2037898302078247,
    "learning_rate": 7.517619420516837e-06,
    "epoch": 2.89760348583878,
    "step": 1330
  },
  {
    "loss": 0.859,
    "grad_norm": 0.22620607912540436,
    "learning_rate": 5.951448707909162e-06,
    "epoch": 2.9193899782135078,
    "step": 1340
  },
  {
    "loss": 0.9146,
    "grad_norm": 0.22018420696258545,
    "learning_rate": 4.385277995301488e-06,
    "epoch": 2.9411764705882355,
    "step": 1350
  },
  {
    "eval_loss": 1.151746153831482,
    "eval_runtime": 41.5375,
    "eval_samples_per_second": 9.269,
    "eval_steps_per_second": 2.335,
    "epoch": 2.9411764705882355,
    "step": 1350
  },
  {
    "loss": 0.9253,
    "grad_norm": 0.16852320730686188,
    "learning_rate": 2.8191072826938138e-06,
    "epoch": 2.962962962962963,
    "step": 1360
  },
  {
    "loss": 0.8719,
    "grad_norm": 0.1732211858034134,
    "learning_rate": 1.2529365700861394e-06,
    "epoch": 2.9847494553376905,
    "step": 1370
  },
  {
    "train_runtime": 9663.9489,
    "train_samples_per_second": 2.28,
    "train_steps_per_second": 0.142,
    "total_flos": 9.159216066000323e+17,
    "train_loss": 1.012435947541491,
    "epoch": 3.0,
    "step": 1377
  },
  {
    "eval_loss": 1.1333292722702026,
    "eval_runtime": 41.6085,
    "eval_samples_per_second": 9.253,
    "eval_steps_per_second": 2.331,
    "epoch": 3.0,
    "step": 1377
  },
  {
    "eval_loss": 1.137364149093628,
    "eval_runtime": 41.6543,
    "eval_samples_per_second": 9.243,
    "eval_steps_per_second": 2.329,
    "epoch": 3.0,
    "step": 1377
  }
]